server.port=8080

# LLM configuration (will be used later)
llm.mode=cloud
llm.provider=claude
ollama.model=mistral:7b-instruct-q4
